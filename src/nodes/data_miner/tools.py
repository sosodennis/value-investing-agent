"""
Node A: Data Miner - Private Tools

This module contains SEC-specific tools for the Data Miner node:
1. SEC EDGAR download utilities
2. HTML to Markdown conversion
3. Basic text cleaning (removes HTML tags, preserves structure)

Note: With Gemini's large context window, we can pass large
10-K sections directly to the LLM without complex chunking logic.
"""

import os
import glob
import re
from sec_edgar_downloader import Downloader
from bs4 import BeautifulSoup
from markdownify import markdownify

# å®šç¾©æ•¸æ“šç·©å­˜ç›®éŒ„ (å°ˆæ¡ˆæ ¹ç›®éŒ„/data)
# ç¢ºä¿è·¯å¾‘ç›¸å°æ–¼ç•¶å‰æ–‡ä»¶æ˜¯æ­£ç¢ºçš„
BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../../data"))


def get_sec_downloader(user_agent: str) -> Downloader:
    """
    Create and return a SEC EDGAR Downloader instance.
    
    Args:
        user_agent: User agent string in format "Name <email@domain.com>"
        
    Returns:
        Downloader instance
    """
    return Downloader("MyAIOrg", user_agent, BASE_DIR)


def fetch_10k_text(ticker: str, user_agent: str) -> str:
    """
    Download the latest 10-K filing and extract financial statements text.
    
    Steps:
    1. Download latest 10-K from SEC EDGAR
    2. Extract financial statements section (Markdown format)
    3. Return cleaned text for LLM processing
    
    Args:
        ticker: Stock ticker symbol (e.g., "AAPL")
        user_agent: User agent string for SEC API
        
    Returns:
        str: Markdown-formatted text containing financial statements
        
    Raises:
        ValueError: If download fails or file not found
        FileNotFoundError: If downloaded file cannot be located
    """
    try:
        print(f"ğŸ“¥ [Tool] æ­£åœ¨å¾ SEC ä¸‹è¼‰ {ticker} çš„ 10-K (User-Agent: {user_agent})...")
        dl = get_sec_downloader(user_agent)
        
        # ä¸‹è¼‰ 1 ä»½æœ€æ–°çš„ 10-K
        # download_details=False åªä¸‹è¼‰ä¸»æ–‡æª”
        num_downloaded = dl.get("10-K", ticker, limit=1, download_details=False)
        
        if num_downloaded == 0:
            raise ValueError("SEC ä¸‹è¼‰å™¨æœªæ‰¾åˆ°ä»»ä½•æ–‡ä»¶")
        
        # --- [Fix] ä¿®æ”¹æ–‡ä»¶æŸ¥æ‰¾é‚è¼¯ï¼šæ”¯æŒ HTML å’Œ TXT æ ¼å¼ ---
        
        # å®šç¾©åŸºç¤æœç´¢è·¯å¾‘: data/sec-edgar-filings/{ticker}/10-K/{accession}/
        base_search_path = os.path.join(BASE_DIR, "sec-edgar-filings", ticker, "10-K", "*")
        
        # ç­–ç•¥ A: å…ˆæ‰¾ HTML (Primary Document)
        html_files = glob.glob(os.path.join(base_search_path, "*.html"))
        
        # ç­–ç•¥ B: å†æ‰¾ TXT (Full Submission) - æ–°ç‰ˆæœ¬ sec-edgar-downloader å¯èƒ½ä¸‹è¼‰æ­¤æ ¼å¼
        txt_files = glob.glob(os.path.join(base_search_path, "*.txt"))
        
        target_file = None
        
        if html_files:
            target_file = html_files[0]
            print("ğŸ“„ [Tool] æ‰¾åˆ° HTML æ ¼å¼æ–‡ä»¶")
        elif txt_files:
            target_file = txt_files[0]
            print("ğŸ“„ [Tool] æ‰¾åˆ° TXT (Full Submission) æ ¼å¼æ–‡ä»¶")
        else:
            raise FileNotFoundError(f"ç„¡æ³•åœ¨ {base_search_path} æ‰¾åˆ° HTML æˆ– TXT æ–‡ä»¶")
        
        print(f"ğŸ“„ [Tool] è®€å–æ–‡ä»¶è·¯å¾‘: {target_file}")
        with open(target_file, "r", encoding="utf-8", errors="ignore") as f:
            html_content = f.read()
        
        print(f"ğŸ§¹ [Tool] æ­£åœ¨æ¸…æ´—å…§å®¹ (åŸå§‹å¤§å°: {len(html_content)} chars)...")
        
        # --- æ™ºèƒ½æˆªå–ç­–ç•¥ ---
        # å³ä½¿æ˜¯ .txt çš„ full-submissionï¼ŒBeautifulSoup ä¹Ÿèƒ½è§£æå…¶ä¸­çš„ HTML æ¨™ç±¤
        # BeautifulSoup æœƒè‡ªå‹•å¿½ç•¥ SEC-HEADER é€™ç¨®é HTML æ¨™ç±¤ï¼Œåªä¿ç•™è¡¨æ ¼
        soup = BeautifulSoup(html_content, 'lxml')
        text_content = soup.get_text(" ", strip=True)  # å…ˆç²—ç•¥è½‰æ–‡æœ¬ç”¨æ–¼å®šä½
        
        # å®šä½é—œéµè© (å¤§å°å¯«ä¸æ•æ„Ÿ)
        # 10-K Item 8 é€šå¸¸åŒ…å« Financial Statements
        targets = [
            "Consolidated Statements of Operations",
            "CONSOLIDATED STATEMENTS OF OPERATIONS",
            "Consolidated Statements of Income",
            "CONSOLIDATED STATEMENTS OF INCOME"
        ]
        
        start_idx = -1
        for t in targets:
            idx = text_content.find(t)
            if idx != -1:
                start_idx = idx
                print(f"ğŸ“ [Tool] å®šä½åˆ°é—œéµè©: {t}")
                break
        
        # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå°±å–æ–‡æª”å¾ŒåŠéƒ¨åˆ† (é€šå¸¸è²¡å ±åœ¨å¾Œé¢)
        if start_idx == -1:
            print("âš ï¸ [Tool] æœªæ‰¾åˆ°é—œéµè©ï¼Œä½¿ç”¨æ–‡æª”å¾ŒåŠéƒ¨åˆ†...")
            start_idx = len(html_content) // 2
        
        # --- è½‰æ›ç‚º Markdown ---
        print("ğŸ”„ [Tool] æ­£åœ¨è½‰æ›ç‚º Markdown (é€™å¯èƒ½éœ€è¦å¹¾ç§’é˜)...")
        # markdownify æœƒè‡ªå‹•å¿½ç•¥ SEC-HEADER é€™ç¨®é HTML æ¨™ç±¤ï¼Œåªä¿ç•™è¡¨æ ¼
        # å³ä½¿æ˜¯ full-submission.txtï¼Œå…¶ä¸­çš„ HTML æ¨™ç±¤ä¹Ÿèƒ½è¢«æ­£ç¢ºè½‰æ›
        full_markdown = markdownify(html_content)
        
        # åœ¨ Markdown ä¸­å†æ‰¾ä¸€æ¬¡
        md_start_idx = -1
        for t in targets:
            idx = full_markdown.find(t)
            if idx != -1:
                md_start_idx = idx
                break
        
        if md_start_idx != -1:
            # æˆªå–é—œéµè©å¾Œé¢çš„ 50,000 å€‹å­—ç¬¦ (è¶³å¤ åŒ…å«æç›Šè¡¨ã€è³‡ç”¢è² å‚µè¡¨)
            # Gemini Context å¾ˆé•·ï¼Œæˆ‘å€‘å¯ä»¥å¤§æ–¹ä¸€é»
            return full_markdown[md_start_idx : md_start_idx + 50000]
        else:
            # å¯¦åœ¨æ‰¾ä¸åˆ°ï¼Œè¿”å›ä¸­é–“åˆ°çµå°¾çš„ 50,000 å­—ç¬¦
            mid = len(full_markdown) // 2
            return full_markdown[mid : mid + 50000]
            
    except Exception as e:
        print(f"âŒ [Tool Error] {str(e)}")
        # æ‹‹å‡ºç•°å¸¸ï¼Œè®“ Node æ•ç²ä¸¦è½‰ç‚º error ç‹€æ…‹
        raise e
