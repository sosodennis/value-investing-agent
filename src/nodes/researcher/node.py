"""
Node C: Researcher - Main Node Logic

This node orchestrates deep research:
1. Searches market sentiment using Tavily API
2. Analyzes competitive landscape
3. Synthesizes qualitative insights using Gemini
"""

import os
from langchain_google_genai import ChatGoogleGenerativeAI
from src.state import AgentState
from src.models.analysis import QualitativeAnalysis
from src.nodes.researcher.tools import search_market_news


def researcher_node(state: AgentState) -> dict:
    """
    Researcher node function.
    
    This function:
    1. Searches market news using Tavily
    2. Analyzes SEC 10-K text (MD&A section)
    3. Synthesizes qualitative insights using Gemini
    
    Returns:
        dict: Updated state with qualitative_analysis (QualitativeAnalysis) or error
    """
    ticker = state['ticker']
    tasks = state.get("investigation_tasks", [])
    
    print(f"\nğŸ” [Node C: Researcher] æ­£åœ¨åˆ†æ {ticker} çš„åŸºæœ¬é¢èˆ‡æƒ…ç·’...")
    print(f"ğŸ“‹ [Investigation] å¾…èª¿æŸ¥çš„ç•°å¸¸é»: {len(tasks)} å€‹")
    
    # 1. æ§‹å»ºæœç´¢æŸ¥è©¢
    # åŸºç¤æŸ¥è©¢
    queries = [f"{ticker} stock analyst rating and risks 2025"]
    
    # [Fix] åŠ å…¥ä¾†è‡ª Calculator çš„å®šå‘æŸ¥è©¢
    if tasks:
        print(f"ğŸ•µï¸â€â™€ï¸ [Deep Dive] æª¢æ¸¬åˆ°ç•°å¸¸ï¼Œè¿½åŠ å®šå‘æœç´¢: {tasks}")
        queries.extend(tasks)
    
    # 2. åŸ·è¡Œæœç´¢ (å¾ªç’°èª¿ç”¨ search_market_news)
    news_context = ""
    for q in queries:
        result = search_market_news(q)  # ç¾åœ¨æ¥å—ä»»æ„æŸ¥è©¢å­—ç¬¦ä¸²
        news_context += f"\n=== Search: {q} ===\n{result}\n"
    
    # 2. ç²å–å…§éƒ¨ä¿¡æ¯ (SEC Text)
    # æˆ‘å€‘åˆ©ç”¨ State ä¸­å·²ç¶“ä¿å­˜çš„ 10-K æ–‡æœ¬ (ç”± Node A ä¸‹è¼‰)
    sec_text = state.get("sec_text_chunk", "")[:50000]  # é™åˆ¶é•·åº¦ä»¥å…éé•·ï¼Œé›– Gemini å¯åƒ 1M
    
    # 3. ç²å–è²¡å‹™æŒ‡æ¨™ (Node B çš„ç”¢å‡º)
    metrics = state.get("valuation_metrics")
    metrics_context = f"P/E: {metrics.pe_ratio}, Status: {metrics.valuation_status}" if metrics else "N/A"
    
    # 4. èª¿ç”¨ Gemini é€²è¡Œç¶œåˆåˆ†æ
    print("ğŸ¤– èª¿ç”¨ Gemini ç¶œåˆåˆ†æ (News + SEC + Financials)...")
    
    try:
        llm = ChatGoogleGenerativeAI(
            model="gemini-2.0-flash-lite",
            temperature=0.3  # ç¨å¾®å¢åŠ ä¸€é»å‰µé€ åŠ›ä»¥é€²è¡Œç¸½çµ
        )
        
        structured_llm = llm.with_structured_output(QualitativeAnalysis)
        special_instruction_block = ""
    
        if tasks:
            task_list_str = "\n".join([f"- {task}" for task in tasks])
            special_instruction_block = f"""
    ã€ç‰¹åˆ¥æŒ‡ä»¤ (ä¾†è‡ªé‡åŒ–åˆ†æçµ„)ã€‘
    ä¸Šæ¸¸è¨ˆç®—ç¯€é»ç™¼ç¾äº†ä»¥ä¸‹æ•¸æ“šç•°å¸¸ï¼Œè«‹å‹™å¿…æ ¹æ“šæœç´¢çµæœçµ¦å‡ºè§£é‡‹ï¼š
    {task_list_str}

    è«‹é‡é»èª¿æŸ¥ä¸Šè¿°å•é¡Œï¼Œè«‹åœ¨å ±å‘Šä¸­å°ˆé–€é–‹é—¢ç« ç¯€èªªæ˜ã€‚
    """
        prompt = f"""
ä½ æ˜¯ä¸€ä½è¯çˆ¾è¡—è³‡æ·±æ¬Šç›Šåˆ†æå¸«ã€‚è«‹æ ¹æ“šæä¾›çš„æ•¸æ“šï¼Œå° {ticker} é€²è¡Œæ·±åº¦å®šæ€§åˆ†æã€‚

ã€è¼¸å…¥æ•¸æ“šã€‘

1. ä¼°å€¼æŒ‡æ¨™: {metrics_context}

2. æœ€æ–°å¸‚å ´æ–°è:

{news_context}

3. SEC 10-K è²¡å ±ç‰‡æ®µ (MD&A):

{sec_text}

{special_instruction_block}

ã€ä»»å‹™ã€‘

è«‹ç¶œåˆä»¥ä¸Šä¿¡æ¯ï¼Œç”Ÿæˆä¸€ä»½åˆ†æå ±å‘Šã€‚ç‰¹åˆ¥è¦æ³¨æ„ï¼š

- è§£é‡‹ç‚ºä»€éº¼è©²å…¬å¸è™•æ–¼ {metrics.valuation_status if metrics else 'Unknown'} ç‹€æ…‹ï¼Ÿ(ä¾‹å¦‚ï¼šæ˜¯å› ç‚ºé«˜å¢é•·é æœŸå°è‡´çš„é«˜ P/E å—ï¼Ÿ)

- å¾æ–°èä¸­æå–åˆ†æå¸«è§€é»ã€‚

- å¾è²¡å ±ä¸­æå–ç®¡ç†å±¤å°æœªä¾†çš„å±•æœ›ã€‚

- è­˜åˆ¥é—œéµå¢é•·é©…å‹•åŠ›å’Œä¸»è¦é¢¨éšªã€‚
"""
        
        result = structured_llm.invoke(prompt)
        print(f"ğŸ’¡ åˆ†æå®Œæˆ: Sentiment={result.market_sentiment}")
        
        return {
            "qualitative_analysis": result,
            "error": None
        }
        
    except Exception as e:
        print(f"âŒ Researcher Error: {e}")
        import traceback
        traceback.print_exc()
        return {"error": "research_failed"}
