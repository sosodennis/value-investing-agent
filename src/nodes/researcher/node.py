"""
Node C: Researcher - Main Node Logic

This node orchestrates deep research:
1. Searches market sentiment using Tavily API
2. Analyzes competitive landscape
3. Synthesizes qualitative insights using Gemini
"""

import os
from langchain_google_genai import ChatGoogleGenerativeAI
from src.state import AgentState
from src.models.analysis import QualitativeAnalysis
from src.nodes.researcher.tools import search_market_news


def researcher_node(state: AgentState) -> dict:
    """
    Researcher node function.
    
    This function:
    1. Searches market news using Tavily
    2. Analyzes SEC 10-K text (MD&A section)
    3. Synthesizes qualitative insights using Gemini
    
    Returns:
        dict: Updated state with qualitative_analysis (QualitativeAnalysis) or error
    """
    ticker = state['ticker']
    print(f"\nğŸ” [Node C: Researcher] æ­£åœ¨åˆ†æ {ticker} çš„åŸºæœ¬é¢èˆ‡æƒ…ç·’...")
    
    # 1. ç²å–å¤–éƒ¨ä¿¡æ¯ (News)
    news_context = search_market_news(ticker)
    
    # 2. ç²å–å…§éƒ¨ä¿¡æ¯ (SEC Text)
    # æˆ‘å€‘åˆ©ç”¨ State ä¸­å·²ç¶“ä¿å­˜çš„ 10-K æ–‡æœ¬ (ç”± Node A ä¸‹è¼‰)
    sec_text = state.get("sec_text_chunk", "")[:50000]  # é™åˆ¶é•·åº¦ä»¥å…éé•·ï¼Œé›– Gemini å¯åƒ 1M
    
    # 3. ç²å–è²¡å‹™æŒ‡æ¨™ (Node B çš„ç”¢å‡º)
    metrics = state.get("valuation_metrics")
    metrics_context = f"P/E: {metrics.pe_ratio}, Status: {metrics.valuation_status}" if metrics else "N/A"
    
    # 4. èª¿ç”¨ Gemini é€²è¡Œç¶œåˆåˆ†æ
    print("ğŸ¤– èª¿ç”¨ Gemini ç¶œåˆåˆ†æ (News + SEC + Financials)...")
    
    try:
        llm = ChatGoogleGenerativeAI(
            model="gemini-2.0-flash-lite",
            temperature=0.3  # ç¨å¾®å¢åŠ ä¸€é»å‰µé€ åŠ›ä»¥é€²è¡Œç¸½çµ
        )
        
        structured_llm = llm.with_structured_output(QualitativeAnalysis)
        
        prompt = f"""
ä½ æ˜¯ä¸€ä½è¯çˆ¾è¡—è³‡æ·±æ¬Šç›Šåˆ†æå¸«ã€‚è«‹æ ¹æ“šæä¾›çš„æ•¸æ“šï¼Œå° {ticker} é€²è¡Œæ·±åº¦å®šæ€§åˆ†æã€‚

ã€è¼¸å…¥æ•¸æ“šã€‘

1. ä¼°å€¼æŒ‡æ¨™: {metrics_context}

2. æœ€æ–°å¸‚å ´æ–°è:

{news_context}

3. SEC 10-K è²¡å ±ç‰‡æ®µ (MD&A):

{sec_text}

ã€ä»»å‹™ã€‘

è«‹ç¶œåˆä»¥ä¸Šä¿¡æ¯ï¼Œç”Ÿæˆä¸€ä»½åˆ†æå ±å‘Šã€‚ç‰¹åˆ¥è¦æ³¨æ„ï¼š

- è§£é‡‹ç‚ºä»€éº¼è©²å…¬å¸è™•æ–¼ {metrics.valuation_status if metrics else 'Unknown'} ç‹€æ…‹ï¼Ÿ(ä¾‹å¦‚ï¼šæ˜¯å› ç‚ºé«˜å¢é•·é æœŸå°è‡´çš„é«˜ P/E å—ï¼Ÿ)

- å¾æ–°èä¸­æå–åˆ†æå¸«è§€é»ã€‚

- å¾è²¡å ±ä¸­æå–ç®¡ç†å±¤å°æœªä¾†çš„å±•æœ›ã€‚

- è­˜åˆ¥é—œéµå¢é•·é©…å‹•åŠ›å’Œä¸»è¦é¢¨éšªã€‚
"""
        
        result = structured_llm.invoke(prompt)
        print(f"ğŸ’¡ åˆ†æå®Œæˆ: Sentiment={result.market_sentiment}")
        
        return {
            "qualitative_analysis": result,
            "error": None
        }
        
    except Exception as e:
        print(f"âŒ Researcher Error: {e}")
        import traceback
        traceback.print_exc()
        return {"error": "research_failed"}
